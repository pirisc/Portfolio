{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Natural Language Processing with Disaster Tweets\n",
        "\n",
        "The main goal of this competition is predict which Tweets are about real disasters and which oner are not.\n",
        "\n",
        "* Link to the competition website: https://www.kaggle.com/competitions/nlp-getting-started/overview"
      ],
      "metadata": {
        "id": "cqTcTSH9PJit"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Data"
      ],
      "metadata": {
        "id": "kej4new0Pler"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "metadata": {
        "id": "aYrLwGmiP-9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "# Retrieve credentials\n",
        "KAGGLE_KEY =  userdata.get('KAGGLE_KEY')\n",
        "KAGGLE_USERNAME = userdata.get('KAGGLE_USERNAME')\n",
        "\n",
        "\n",
        "# Set environmental variables with %env to better work with kaggle\n",
        "%env KAGGLE_USERNAME=$KAGGLE_USERNAME\n",
        "%env KAGGLE_KEY=$KAGGLE_KEY"
      ],
      "metadata": {
        "id": "YAY-1llHW2x-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import os\n",
        "import kaggle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sklearn"
      ],
      "metadata": {
        "id": "UbH7jiHCa01y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c nlp-getting-started"
      ],
      "metadata": {
        "id": "xuF0HKw8W9bb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/nlp-getting-started.zip"
      ],
      "metadata": {
        "id": "nTfV0wsXXA8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inspect Data"
      ],
      "metadata": {
        "id": "LOknHBGmXE-U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "test_df = pd.read_csv('/content/test.csv')\n",
        "train_df = pd.read_csv('/content/train.csv')"
      ],
      "metadata": {
        "id": "ABq7ONykXIWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check train_df\n",
        "train_df.head()"
      ],
      "metadata": {
        "id": "h8W9pjXuXPQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.shape"
      ],
      "metadata": {
        "id": "PZhkoO04Oh_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.info()"
      ],
      "metadata": {
        "id": "Uhh-TeWvZi-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check how much data is missing\n",
        "train_df.isnull().sum()"
      ],
      "metadata": {
        "id": "eDFf0a_5ZlqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How many examples of each class are\n",
        "train_df.target.value_counts()"
      ],
      "metadata": {
        "id": "XoINh3IZNnHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare data\n",
        "\n",
        "To prepare our data we need a few steps:\n",
        "1. we need to lowecase our text so all the tokens are equal. Meaning \"Fire\" is equl to \"FIRE\" or \"fire\"\n",
        "\n",
        "2. We need to remove the URLs that are considered noised for a ML classifier\n",
        "\n",
        "3. We also need to remove Stop Words that provide low-information."
      ],
      "metadata": {
        "id": "lvjmjihglN7E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download(\"punkt_tab\")\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def clean_text(text):\n",
        "  # Lowercasing text\n",
        "  text = text.lower()\n",
        "\n",
        "  # Removing URLs\n",
        "  text = re.sub(r'https?:\\/\\/.*', \" \" , text)\n",
        "\n",
        "  # Tokenize text\n",
        "  tokenized_text = nltk.word_tokenize(text)\n",
        "\n",
        "  # Filter stop words\n",
        "  filtered_tokens = [word for word in tokenized_text if word not in stop_words]\n",
        "\n",
        "  # Join tokens back into a single string\n",
        "  text = ' '.join(filtered_tokens)\n",
        "\n",
        "  return text\n"
      ],
      "metadata": {
        "id": "dJIphxInZrjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split data"
      ],
      "metadata": {
        "id": "fvdhO6pfP_RS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create X\n",
        "X = train_df.drop(\"target\", axis= 1)\n",
        "# Create y\n",
        "y = train_df[\"target\"]"
      ],
      "metadata": {
        "id": "KfkgoKHGQDjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Split the data\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "len(X_train), len(X_test), len(y_train), len(y_test)"
      ],
      "metadata": {
        "id": "5puJ0hwdQQBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we need to use our `clean_text()` function to handle lowercasing, URL removal and stop word filtering.\n"
      ],
      "metadata": {
        "id": "S9oCT2cUQ4r4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the cleaning function to the 'text' column of the training set\n",
        "X_train['cleaned_text'] = X_train['text'].apply(clean_text)\n",
        "\n",
        "# Do the same for the testing set\n",
        "X_test['cleaned_text'] = X_test['text'].apply(clean_text)"
      ],
      "metadata": {
        "id": "AEYVCii2SYIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a Baseline model"
      ],
      "metadata": {
        "id": "AKbuveXJQmLM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfid = TfidfVectorizer(ngram_range=(1,3), max_df=0.9)\n",
        "X_train_vectors = tfid.fit_transform(X_train['cleaned_text'])\n",
        "# no fit() here to prevent data leakage\n",
        "X_test_vectors = tfid.transform(X_test['cleaned_text'])"
      ],
      "metadata": {
        "id": "xf_4qvV-UcTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model_0 = LogisticRegression(random_state = 42)\n",
        "model_0.fit(X_train_vectors, y_train)"
      ],
      "metadata": {
        "id": "pWNSLHe0VFqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate our baseline model\n",
        "baseline_score  = model_0.score(X_test_vectors, y_test)\n",
        "baseline_score"
      ],
      "metadata": {
        "id": "kLiFIA8dVRg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "baseline_preds = model_0.predict(X_test_vectors)\n",
        "baseline_preds[:10]"
      ],
      "metadata": {
        "id": "BPk1EGAhVvR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to evaluate: accuracy, precision, recall, f1-score\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def calculate_results(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
        "\n",
        "  Args:\n",
        "  -----\n",
        "  y_true = true labels in the form of a 1D array\n",
        "  y_pred = predicted labels in the form of a 1D array\n",
        "\n",
        "  Returns a dictionary of accuracy, precision, recall, f1-score.\n",
        "  \"\"\"\n",
        "  # Calculate model accuracy\n",
        "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "  # Calculate model precision, recall and f1 score using \"weighted\" average\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "  model_results = {\"accuracy\": model_accuracy,\n",
        "                  \"precision\": model_precision,\n",
        "                  \"recall\": model_recall,\n",
        "                  \"f1\": model_f1}\n",
        "  return model_results"
      ],
      "metadata": {
        "id": "UTtQTtfMV1y3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_results = calculate_results(y_test, baseline_preds)\n",
        "baseline_results"
      ],
      "metadata": {
        "id": "pLhWJSxmWKfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5KdockZfWPqO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}